# sagemaker_mme_triton

How to run inference on multiple models on a GPU instance in SageMaker via Triton
